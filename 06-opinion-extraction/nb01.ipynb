{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import Counter, namedtuple\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from torch import nn\n",
    "from transformers import BertModel\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from typing import List, Tuple\n",
    "import config\n",
    "from copy import deepcopy, copy\n",
    "import importlib\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FrameBatch = namedtuple(\"FrameBatch\", \"sentence_ids, sentences, sentence_token_ids, mask, frames\")\n",
    "\n",
    "def tokenize(tokenizer, tokens) -> Tuple[List[str], List[int]]:\n",
    "    '''\n",
    "    tokenizer is pretrained transformer model tokenizer\n",
    "    tokens is list of str\n",
    "\n",
    "    return:\n",
    "        new tokens  : list of str\n",
    "        mapping     : list of int\n",
    "    \n",
    "    prepend [AUTHOR] to new tokens\n",
    "    if old tokens has m words and new tokens has n words,\n",
    "    then mapping is m + 2 dimensional and each value lies between 0 and n\n",
    "\n",
    "    mapping[i] = j means that ith word of old tokens begins at jth\n",
    "    position in new tokens\n",
    "    '''\n",
    "    mapping = np.zeros(len(tokens) + 2, dtype=int)\n",
    "    new_tokens = [\"[AUTHOR]\"]\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        ttokens = tokenizer.tokenize(token)\n",
    "        new_tokens.extend(ttokens)\n",
    "        mapping[i + 2] = mapping[i + 1] + len(ttokens)\n",
    "\n",
    "    mapping[1:] += 1\n",
    "    return new_tokens, mapping\n",
    "\n",
    "def create_frame_label(mapping, frame_tuples, max_seq_len) -> np.ndarray:\n",
    "    '''\n",
    "    mapping         : list of int\n",
    "    frame_tuples    : set of frame tuples\n",
    "                      each tuple is 6-dimensional: holder, predicate, and target\n",
    "                      correct it by adding 1\n",
    "    max_seq_len     : int\n",
    "                      max sentence length\n",
    "                      if an argument's span exceeds max_seq_len, ignore the frame\n",
    "    \n",
    "    return:\n",
    "        frame label : numpy int array B x L x F\n",
    "                      B is the number of frame tuples\n",
    "                      L = max_seq_len\n",
    "                      F = 3 because of 3 arguments: holder, predicate, and target\n",
    "                      frame label is 0 = O, 1 = B, or 2 = I\n",
    "    '''\n",
    "    frame_labels = []\n",
    "\n",
    "    for frame_tuple in frame_tuples:\n",
    "        frame_label = np.zeros((max_seq_len, 3), dtype=int)\n",
    "        if mapping[max(frame_tuple[1], frame_tuple[3], frame_tuple[5])] >= max_seq_len:\n",
    "            continue\n",
    "\n",
    "        for j in range(mapping[frame_tuple[0] + 1], mapping[frame_tuple[1] + 1]):\n",
    "            if j == mapping[frame_tuple[0] + 1]:\n",
    "                frame_label[j, 0] = 1\n",
    "            else:\n",
    "                frame_label[j, 0] = 2\n",
    "        \n",
    "        for j in range(mapping[frame_tuple[2] + 1], mapping[frame_tuple[3] + 1]):\n",
    "            if j == mapping[frame_tuple[2] + 1]:\n",
    "                frame_label[j, 1] = 1\n",
    "            else:\n",
    "                frame_label[j, 1] = 2\n",
    "        \n",
    "        for j in range(mapping[frame_tuple[4] + 1], mapping[frame_tuple[5] + 1]):\n",
    "            if j == mapping[frame_tuple[4] + 1]:\n",
    "                frame_label[j, 2] = 1\n",
    "            else:\n",
    "                frame_label[j, 2] = 2\n",
    "\n",
    "        frame_labels.append(frame_label)\n",
    "    \n",
    "    frame_label = np.array(frame_labels)\n",
    "    return frame_label\n",
    "\n",
    "class FrameDataset:\n",
    "\n",
    "    def __init__(self, docids, train=True) -> None:\n",
    "        '''\n",
    "        params:\n",
    "            docids      : list of str docids\n",
    "            train       : bool\n",
    "            sentence_ids: numpy array of shape D x 2\n",
    "                          file name (str) and sentence index (int)\n",
    "            sentences   : str numpy array of shape D x L\n",
    "                          padded tokens are [PAD]\n",
    "            sentence_token_ids\n",
    "                        : torch long tensor of shape D x L\n",
    "            mask        : torch float tensor of shape D x L\n",
    "            frames      : torch long tensor of shape D x L x F\n",
    "        \n",
    "        D is number of direct subjective frames\n",
    "        L is max seq length\n",
    "        F = 3 for number of argument types: holder, predicate, target\n",
    "\n",
    "        if train is true, sentence with no direct subjective frame are excluded\n",
    "        else, they are included exactly once\n",
    "        '''\n",
    "        self.docids = docids\n",
    "        self.train = train\n",
    "\n",
    "        sentences = []\n",
    "        sentence_ids = []\n",
    "        sentence_token_ids = []\n",
    "        frames = []\n",
    "        tokenizer = BertTokenizer.from_pretrained(config.embed_model_name)\n",
    "        tokenizer.vocab[\"[AUTHOR]\"] = tokenizer.vocab.pop(\"[unused1]\")\n",
    "        \n",
    "        for docid in self.docids:\n",
    "            doc = json.load(open(os.path.join(config.DATA_FOLDER, \"mpqa2-processed\", docid, \"tokenized.json\")))\n",
    "\n",
    "            for i, sentence in enumerate(doc):\n",
    "                \n",
    "                frame_tuples = set()\n",
    "                for frame in sentence[\"dse\"]:\n",
    "                    if isinstance(frame[\"dse-span\"], list) and isinstance(frame[\"target-span\"], list) and (isinstance(frame[\"holder-span\"], list) or frame[\"holder-type\"] in [\"writer\", \"implicit\"]):\n",
    "                        if isinstance(frame[\"holder-span\"], list):\n",
    "                            frame_tuples.add(tuple(frame[\"holder-span\"] + frame[\"dse-span\"] + frame[\"target-span\"]))\n",
    "                        else:\n",
    "                            frame_tuples.add(tuple([-1, 0] + frame[\"dse-span\"] + frame[\"target-span\"]))\n",
    "                \n",
    "                new_tokens, mapping = tokenize(tokenizer, sentence[\"tokens\"])\n",
    "                frame = create_frame_label(mapping, frame_tuples, config.max_seq_len)\n",
    "                if frame.size:\n",
    "                    for _ in range(frame.shape[0]):\n",
    "                        sentences.append(new_tokens)\n",
    "                        sentence_ids.append([docid, i])\n",
    "                        sentence_token_ids.append(tokenizer.convert_tokens_to_ids(new_tokens))\n",
    "                    frames.append(frame)\n",
    "                elif not self.train:\n",
    "                    sentences.append(new_tokens)\n",
    "                    sentence_ids.append([docid, i])\n",
    "                    sentence_token_ids.append(tokenizer.convert_tokens_to_ids(new_tokens))\n",
    "                    frames.append(np.zeros((1, config.max_seq_len, 3), dtype=int))\n",
    "        \n",
    "        self.sentences = pad_sequences(sentences, maxlen=config.max_seq_len, padding=\"post\", truncating=\"post\", value=\"[PAD]\", dtype=object).astype(str)\n",
    "\n",
    "        self.sentence_ids = np.array(sentence_ids)\n",
    "\n",
    "        sentence_token_ids = pad_sequences(sentence_token_ids, maxlen=config.max_seq_len, padding=\"post\", truncating=\"post\", value=tokenizer.vocab[\"[PAD]\"])\n",
    "        self.sentence_token_ids = torch.LongTensor(sentence_token_ids)\n",
    "        \n",
    "        mask = np.zeros(self.sentence_token_ids.shape, dtype=float)\n",
    "        for i, sentence in enumerate(self.sentences):\n",
    "            mask[i, : len(sentence)] = 1\n",
    "        self.mask = torch.FloatTensor(mask)\n",
    "\n",
    "        self.frames = torch.LongTensor(np.vstack(frames))\n",
    "\n",
    "    def to(self, device):\n",
    "        self.sentence_token_ids = self.sentence_token_ids.to(device)\n",
    "        self.mask = self.mask.to(device)\n",
    "        self.frames = self.frames.to(device)\n",
    "    \n",
    "    def print_frame(self, i):\n",
    "        print(\"SENTENCE ID : {}\".format(self.sentence_ids[i]))\n",
    "        print(\"TOKENS : {}\".format(self.sentences[i]))\n",
    "        frame = self.frames[i].cpu().numpy()\n",
    "        if frame.sum() > 0:\n",
    "            holder = \" \".join(self.sentences[i][frame[:, 0] != 0])\n",
    "            predicate = \" \".join(self.sentences[i][frame[:, 1] != 0])\n",
    "            target = \" \".join(self.sentences[i][frame[:, 2] != 0])\n",
    "            print(\"HOLDER = '{}' PREDICATE = '{}' TARGET = '{}'\".format(holder, predicate, target))\n",
    "        else:\n",
    "            print(\"EMPTY FRAME\")\n",
    "\n",
    "class FrameIterator:\n",
    "\n",
    "    def __init__(self, ds: FrameDataset, batch_size: int, shuffle_batch=True, shuffle_sample=True) -> None:\n",
    "        '''\n",
    "        params:\n",
    "            ds          : FrameDataset\n",
    "            batch_size  : int\n",
    "            shuffle_batch : bool\n",
    "                          if shuffle_batch is true, shuffle the order of batches\n",
    "            shuffle_sample : bool\n",
    "                          if shuffle_sample is true, shuffle the order of samples in adjacent batches\n",
    "        '''\n",
    "        self.ds = ds\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle_batch = shuffle_batch\n",
    "        self.shuffle_sample = shuffle_sample\n",
    "        sentence_lens = (ds.sentences != \"[PAD]\").sum(axis = 1)\n",
    "        self.sorted_index = np.argsort(sentence_lens)\n",
    "        self.n_batches = math.ceil(len(self.sorted_index)/self.batch_size)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        if self.shuffle_batch:\n",
    "            self.batch_sequence = np.random.permutation(self.n_batches)\n",
    "        else:\n",
    "            self.batch_sequence = np.arange(self.n_batches)\n",
    "        self.index = self.sorted_index.copy()\n",
    "        if self.shuffle_sample:\n",
    "            for i in range(self.n_batches - 2):\n",
    "                np.random.shuffle(self.index[i * self.batch_size: (i + 3) * self.batch_size])\n",
    "        self.i = 0\n",
    "        return self\n",
    "    \n",
    "    def __next__(self) -> FrameBatch:\n",
    "        if self.i == self.n_batches:\n",
    "            raise StopIteration\n",
    "        i = self.batch_sequence[self.i]\n",
    "        batch_index = self.index[i * self.batch_size : (i + 1) * self.batch_size]\n",
    "        batch_sentences = self.ds.sentences[batch_index]\n",
    "        batch_sentence_token_ids = self.ds.sentence_token_ids[batch_index]\n",
    "        batch_sentence_ids = self.ds.sentence_ids[batch_index]\n",
    "        batch_mask = self.ds.mask[batch_index]\n",
    "        batch_frames = self.ds.frames[batch_index]\n",
    "        self.i += 1\n",
    "        return FrameBatch(batch_sentence_ids, batch_sentences, batch_sentence_token_ids, batch_mask, batch_frames)\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return self.n_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpqa2_filelist = open(os.path.join(config.RAW_FOLDER, \"database.mpqa.2.0/doclist.attitudeSubset\")).read().splitlines()\n",
    "train_filelist = open(os.path.join(config.SRL4ORL_SPLITS_FOLDER, \"filelist_train0\")).read().splitlines()\n",
    "test_filelist = open(os.path.join(config.SRL4ORL_SPLITS_FOLDER, \"filelist_test0\")).read().splitlines()\n",
    "dev_filelist = open(os.path.join(config.SRL4ORL_SPLITS_FOLDER, \"filelist_dev\")).read().splitlines()\n",
    "device = torch.device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train sentences            : (3193, 100) <U18\n",
      "train sentence ids         : (3193, 2) <U29\n",
      "train sentence token ids   : torch.Size([3193, 100]) torch.int64\n",
      "train mask                 : torch.Size([3193, 100]) torch.float32\n",
      "train frames               : torch.Size([3193, 100, 3]) torch.int64\n",
      "\n",
      "dev sentences            : (2419, 100) <U16\n",
      "dev sentence ids         : (2419, 2) <U29\n",
      "dev sentence token ids   : torch.Size([2419, 100]) torch.int64\n",
      "dev mask                 : torch.Size([2419, 100]) torch.float32\n",
      "dev frames               : torch.Size([2419, 100, 3]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "train_ds = FrameDataset(train_filelist, train=True)\n",
    "dev_ds = FrameDataset(dev_filelist, train=False)\n",
    "\n",
    "train_ds.to(device)\n",
    "dev_ds.to(device)\n",
    "\n",
    "print(\"train sentences            : {} {}\".format(train_ds.sentences.shape, train_ds.sentences.dtype))\n",
    "print(\"train sentence ids         : {} {}\".format(train_ds.sentence_ids.shape, train_ds.sentence_ids.dtype))\n",
    "print(\"train sentence token ids   : {} {}\".format(train_ds.sentence_token_ids.shape, train_ds.sentence_token_ids.dtype))\n",
    "print(\"train mask                 : {} {}\".format(train_ds.mask.shape, train_ds.mask.dtype))\n",
    "print(\"train frames               : {} {}\".format(train_ds.frames.shape, train_ds.frames.dtype))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"dev sentences            : {} {}\".format(dev_ds.sentences.shape, dev_ds.sentences.dtype))\n",
    "print(\"dev sentence ids         : {} {}\".format(dev_ds.sentence_ids.shape, dev_ds.sentence_ids.dtype))\n",
    "print(\"dev sentence token ids   : {} {}\".format(dev_ds.sentence_token_ids.shape, dev_ds.sentence_token_ids.dtype))\n",
    "print(\"dev mask                 : {} {}\".format(dev_ds.mask.shape, dev_ds.mask.dtype))\n",
    "print(\"dev frames               : {} {}\".format(dev_ds.frames.shape, dev_ds.frames.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_and_type(tensor):\n",
    "    return \"{} {}\".format(tensor.dtype, tensor.shape)\n",
    "\n",
    "def permutation_traversal(path, pathlen, nchoices, allpaths):\n",
    "    if pathlen == 0:\n",
    "        allpaths.append(path)\n",
    "    else:\n",
    "        for choice in range(nchoices[len(nchoices) - pathlen]):\n",
    "            newpath = copy(path)\n",
    "            newpath.append(choice)\n",
    "            permutation_traversal(newpath, pathlen - 1, nchoices, allpaths)\n",
    "\n",
    "def permutations(nchoices):\n",
    "    all_possible_sequences = []\n",
    "    permutation_traversal([], len(nchoices), nchoices, all_possible_sequences)\n",
    "    return all_possible_sequences\n",
    "\n",
    "class FrameExtractor(nn.Module):\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super().__init__()\n",
    "        self.n_frame_arguments = hparams.n_frame_arguments\n",
    "        self.n_labels = hparams.n_labels\n",
    "\n",
    "        # TODO: dropout for BertModel\n",
    "        self.embedder = BertModel.from_pretrained(hparams.embed_model_name)\n",
    "        self.embedding_size = self.embedder.config.hidden_size\n",
    "\n",
    "        self.output_embedder = nn.Embedding(self.n_labels + 1, hparams.output_embedding_size)\n",
    "        self.output_embedding_size = hparams.output_embedding_size\n",
    "\n",
    "        self.encoder = nn.LSTM(self.embedding_size, hparams.encoder_hidden_size, \n",
    "                                    num_layers = hparams.encoder_num_layers, batch_first = True, \n",
    "                                    bidirectional = True, dropout = hparams.dropout)\n",
    "        self.encoder_hidden_size = 2 * hparams.encoder_hidden_size\n",
    "\n",
    "        # labels: B, I, O\n",
    "        # arguments: holder, target, predicate\n",
    "        self.decoder = nn.LSTM(self.encoder_hidden_size + self.n_frame_arguments * self.output_embedding_size, hparams.decoder_hidden_size, batch_first = True, dropout = hparams.dropout)\n",
    "        self.decoder_hidden_size = hparams.decoder_hidden_size\n",
    "\n",
    "        self.holder_predictor = nn.Linear(self.decoder_hidden_size, self.n_labels)\n",
    "        self.predicate_predictor = nn.Linear(self.decoder_hidden_size, self.n_labels)\n",
    "        self.target_predictor = nn.Linear(self.decoder_hidden_size, self.n_labels)\n",
    "\n",
    "        self.beam_width = hparams.beam_width\n",
    "        nchoices = [self.beam_width] + [self.n_labels for _ in range(self.n_frame_arguments)]\n",
    "        self.all_permutations = permutations(nchoices)\n",
    "\n",
    "    def forward(self, sentences, mask, frames=None):\n",
    "        '''\n",
    "        sentences   : long tensor of shape B x L\n",
    "        mask        : float tensor of shape B x L\n",
    "        frames      : long tensor of shape B x L x F\n",
    "\n",
    "        B = batch size\n",
    "        L = max seq len\n",
    "        F = self.n_frame_arguments\n",
    "        '''\n",
    "\n",
    "        device = next(self.parameters()).device\n",
    "        batch_size, seq_len = sentences.shape\n",
    "\n",
    "        embedding = self.embedder(sentences, mask).last_hidden_state\n",
    "        # embedding : float tensor of shape B x L x self.embedding_size\n",
    "\n",
    "        encoding, _ = self.encoder(embedding)\n",
    "        # encoding  : float tensor of shape B x L x self.encoder_hidden_size\n",
    "\n",
    "        if frames is not None:\n",
    "            # training code\n",
    "            loss_function = nn.CrossEntropyLoss()\n",
    "            logits_arr = []\n",
    "            nextlabel_frames = torch.zeros(frames.shape, dtype=torch.long, device=device)\n",
    "            nextlabel_frames[:, :-1] = frames[:, 1:]\n",
    "            # nextlabel_frames : long tensor of shape B x L x F\n",
    "\n",
    "            t = torch.full((batch_size, 1, self.n_frame_arguments), fill_value=self.n_labels, dtype=torch.long, device=device)\n",
    "            # t : long tensor of shape B x 1 x self.n_frame_arguments\n",
    "\n",
    "            hidden = torch.randn((1, batch_size, self.decoder_hidden_size), device=device)\n",
    "            cell = torch.randn((1, batch_size, self.decoder_hidden_size), device=device)\n",
    "\n",
    "            for i in range(seq_len):\n",
    "                x = encoding[:, i].reshape((batch_size, 1, -1))\n",
    "                # x : float tensor of shape B x 1 x self.encoder_hidden_size\n",
    "\n",
    "                y = self.output_embedder(t).reshape((batch_size, 1, -1))\n",
    "                # y : float tensor of shape B x 1 x self.n_frame_arguments * self.output_embedding_size\n",
    "\n",
    "                z = torch.cat((x, y), dim = 2)\n",
    "                # z : float tensor of shape B x 1 x (self.encoder_hidden_size + self.n_frame_arguments * self.output_embedding_size)\n",
    "\n",
    "                a, (hidden, cell) = self.decoder(z, (hidden, cell))\n",
    "                # a : float tensor of shape B x 1 x self.decoder_hidden_size\n",
    "\n",
    "                holder_logits = self.holder_predictor(a)\n",
    "                predicate_logits = self.predicate_predictor(a)\n",
    "                target_logits = self.target_predictor(a)\n",
    "                logits = torch.cat((holder_logits, predicate_logits, target_logits), dim = 1)\n",
    "                # logits : float tensor of shape B x self.n_frame_arguments x self.n_labels\n",
    "\n",
    "                logits_arr.append(logits.unsqueeze(dim = 1))\n",
    "                # append reshaped logits of shape B x 1 x self.n_frame_arguments x self.n_labels\n",
    "\n",
    "                t = frames[:, i].reshape((batch_size, 1, -1)).clone()\n",
    "                # t : long tensor of shape B x 1 x self.n_frame_arguments\n",
    "            \n",
    "            logits = torch.cat(logits_arr, dim = 1).reshape((-1, self.n_labels))\n",
    "            # logits : float tensor of shape (B * L * F) x self.n_labels\n",
    "\n",
    "            loss_mask = (frames == 1) | ((frames == 2) & (nextlabel_frames != 0))\n",
    "            # loss mask : bool tensor of shape B x L x F\n",
    "\n",
    "            frames[~loss_mask] = loss_function.ignore_index\n",
    "            \n",
    "            labels = frames.flatten()\n",
    "            # labels : long tensor of shape B * L * F\n",
    "\n",
    "            loss = loss_function(logits, labels)\n",
    "            return loss\n",
    "        \n",
    "        else:\n",
    "            # beam search inference\n",
    "\n",
    "            X = encoding.repeat_interleave(self.beam_width, dim=0)\n",
    "            # X : B * self.beam_width x L x self.encoder_hidden_size\n",
    "\n",
    "            sequences = np.zeros((batch_size * self.beam_width, seq_len, self.n_frame_arguments), dtype=int)\n",
    "            scores = np.zeros((batch_size * self.beam_width,))\n",
    "            prev_label = torch.full((batch_size * self.beam_width, 1, self.n_frame_arguments), fill_value=self.n_labels, dtype=torch.long, device=device)\n",
    "            hidden = torch.randn((1, batch_size * self.beam_width, self.decoder_hidden_size), device=device)\n",
    "            cell = torch.randn((1, batch_size * self.beam_width, self.decoder_hidden_size), device=device)\n",
    "\n",
    "            for i in range(seq_len):\n",
    "                x = X[:, i].reshape((batch_size * self.beam_width, 1, -1))\n",
    "                # x : B * self.beam_width x 1 x self.encoder_hidden_size\n",
    "\n",
    "                y = self.output_embedder(prev_label).reshape((batch_size * self.beam_width, 1, -1))\n",
    "                # y : B * self.beam_width x 1 x self.n_frame_arguments * self.output_embedding_size\n",
    "\n",
    "                z = torch.cat([x, y], dim=2)\n",
    "                # z : B * self.beam_width x 1 x (self.encoder_hidden_size + self.n_frame_arguments * self.output_embedding_size)\n",
    "\n",
    "                a, (new_hidden, new_cell) = self.decoder(z, (hidden, cell))\n",
    "                # a : B * self.beam_width x 1 x self.decoder_hidden_size\n",
    "                # new_hidden, new_cell : 1 x B * self.beam_width x self.decoder_hidden_size\n",
    "\n",
    "                holder_logits = self.holder_predictor(a)\n",
    "                predicate_logits = self.predicate_predictor(a)\n",
    "                target_logits = self.target_predictor(a)\n",
    "                # (holder, predicate, target) logits : B * self.beam_width x 1 x self.n_labels\n",
    "\n",
    "                logits = torch.cat([holder_logits, predicate_logits, target_logits], dim=1)\n",
    "                # logits : B * self.beam_width x self.n_frame_arguments x self.n_labels\n",
    "\n",
    "                logprob = torch.log_softmax(logits, dim=2).cpu().numpy()\n",
    "                # logprob : B * self.beam_width x self.n_frame_arguments x self.n_labels\n",
    "\n",
    "                all_scores = logprob + scores.reshape((batch_size * self.beam_width, 1, 1))\n",
    "                # scores : B * self.beam_width x self.n_frame_arguments x self.n_labels\n",
    "\n",
    "                new_sequences = sequences.copy()\n",
    "                # copy sequences to new_sequences\n",
    "\n",
    "                for j in range(batch_size):\n",
    "                    if i < mask[j].sum():\n",
    "                        sentence_scores = all_scores[j * self.beam_width: (j + 1) * self.beam_width]\n",
    "                        # sentence scores : self.beam_width x self.n_frame_arguments x self.n_labels\n",
    "\n",
    "                        sequence_permutations = copy(self.all_permutations)\n",
    "                        # sequence permutations [int] of size self.beam_width * self.n_labels ^ self.n_frame_arguments\n",
    "\n",
    "                        sequence_permutations_with_score = [permute + [sum(sentence_scores[permute[0], arg, permute[arg + 1]] for arg in range(self.n_frame_arguments))] for permute in sequence_permutations]\n",
    "\n",
    "                        sequence_permutations_with_score = sorted(sequence_permutations_with_score, key=lambda permute: permute[-1], reverse=True)\n",
    "\n",
    "                        sequence_permutations_with_score = sequence_permutations_with_score[:self.beam_width]\n",
    "                        # sequence permutations has the top-k (k = beam width) sequences\n",
    "\n",
    "                        for k, permute in enumerate(sequence_permutations_with_score):\n",
    "                            l = j * self.beam_width + k\n",
    "                            m = j * self.beam_width + permute[0]\n",
    "                            new_sequences[l, :i] = sequences[m, :i]\n",
    "                            new_sequences[l, i] = permute[1:-1]\n",
    "                            scores[l] = permute[-1]\n",
    "                            \n",
    "                            for n in range(self.n_frame_arguments):\n",
    "                                prev_label[l, 0, n] = permute[n + 1]\n",
    "                            \n",
    "                            hidden[0, l] = new_hidden[0, m]\n",
    "                            cell[0, l] = new_cell[0, m]\n",
    "                \n",
    "                sequences = new_sequences\n",
    "\n",
    "            return sequences.reshape(batch_size, self.beam_width, seq_len, self.n_frame_arguments), scores.reshape(batch_size, self.beam_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "89ce7d9bf54abaf122e6a39f319f86f84fcb331f76987a5a2313102b2826ac00"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('opinion': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
